dq-demo-ui-full --max-factors-per-asset-class 100 --start-date 2025-01-01 --end-date 2026-01-31 --business-date 2026-01-31

python -m ui.app_v2 --results-path data/demo_ui_full/processed/dq_results --raw-path data/demo_ui_full/raw/timeseries_raw --membership-path data/demo_ui_full/processed/universe_membership --config-path data/demo_ui_full/processed/ui_full_demo/model_catalog_ui_full.yaml --port 8060


debugging empty Compare tab
python -m pip install -e .
python -m ui.app_v2 --help


python -c "import pandas as pd; d=pd.read_parquet(r'data\\demo_ui_full\\processed\\dq_results'); print('rows',len(d),'flags',int(d['flag'].sum())); print('date',d['date'].min(),'->',d['date'].max()); print('universes',d['universe_name'].nunique()); print('business_dates',d['business_date'].nunique() if 'business_date' in d.columns else 'NA')"

python -m pipeline.run_demo_layer7_dash_ui --app-version v2 --results-path data/demo_ui_full/processed/dq_results --raw-path data/demo_ui_full/raw/timeseries_raw --membership-path data/demo_ui_full/processed/universe_membership --run-callback refresh_compare --sample-args --no-print-layout-tree --no-print-callbacks --no-validate-callback-ids

python -c "import ui.app_v2 as a; print(a.__file__)"

python -c "import os,sys; print(os.getcwd()); print(sys.executable)"

python -c "from ui.app import load_data; d=load_data(r'data/demo_ui_full/processed/dq_results', r'data/demo_ui_full/raw/timeseries_raw', r'data/demo_ui_full/processed/universe_membership', business_date='2026-01-31'); q=d['dq_results']; print('shape',q.shape); print('cols',list(q.columns))"


######### ste[ 2 of debugging 
but on step 4, i got a warning 
app_v2 line 1133, in refresh compare 
            base = f[f["check_id"].astype(str).isin([a, b])].groupby(["risk_factor_id", "date_norm", "check_id"], as_index=False).agg(score=("norm_score", "max"), flag=("flag", "max"))
(error, length of values 12949 does not match length of index 910000)

---? 
set PYTHONPATH=C:\Users\Owner\Desktop\OneDrive\Python\AI\DQ_CheckOpenAI\src

python -c "import ui.app_v2 as a, pandas as pd, dash, dash_ag_grid, plotly; print(a.__file__); print('pandas',pd.__version__,'dash',dash.__version__,'dag',dash_ag_grid.__version__,'plotly',plotly.__version__)"

python -c "from ui.app import load_data; import pandas as pd; d=load_data(r'data/demo_ui_full/processed/dq_results', r'data/demo_ui_full/raw/timeseries_raw', r'data/demo_ui_full/processed/universe_membership', business_date='2026-01-31'); q=d['dq_results'].copy(); q['date_norm']=pd.to_datetime(q['date'], errors='coerce').dt.normalize(); print('rows',len(q),'rf_nunique',q['risk_factor_id'].nunique(),'check_nunique',q['check_id'].nunique()); print('dup_cols',q.columns[q.columns.duplicated()].tolist()); models=q['check_id'].dropna().astype(str).unique().tolist()[:2]; a,b=models[0],models[1]; f=q[q['check_id'].astype(str).isin([a,b])].copy(); f['flag']=f['flag'].astype(bool); base=f.groupby(['risk_factor_id','date_norm','check_id'], as_index=False).agg(score=('norm_score','max'), flag=('flag','max')); print('base',base.shape)"

python -m pip install --upgrade pip
python -m pip install -r requirements.txt
python -m pip install -e .





python -m ui.app_v2 --results-path data/demo_ui_full/processed/dq_results --raw-path data/demo_ui_full/raw/timeseries_raw --membership-path data/demo_ui_full/processed/universe_membership --config-path data/demo_ui_full/processed/ui_full_demo/model_catalog_ui_full.yaml --business-date 2026-01-30 --port 8060






python -m pipeline.run_demo_layer5_runEngine \
  --no-generate-demo-data \
  --raw-path data/raw_manual \
  --processed-path data/processed_manual \
  --config-path configs/model_catalog.yaml \
  --universe-name CP_RATE_CORP \
  --start-date 2007-01-01 \
  --end-date 2026-01-31 \
  --business-date 2026-01-31


python -m ui.app_v2 \
  --results-path data/processed_manual/dq_results \
  --raw-path data/raw_manual/timeseries_raw \
  --membership-path data/processed_manual/universe_membership \
  --config-path configs/model_catalog.yaml \
  --business-date 2026-01-31 \
  --port 8060


run_demo_integrate_with_Mar.py

validate_integration_withMar.ipynb


python -m pipeline.run_demo_integrate_with_Mar ^
  --source-path data\incoming\manual_dataset.xlsx ^
  --source-sheet 0 ^
  --raw-path data\raw_manual ^
  --processed-path data\processed_manual ^
  --config-path configs\model_catalog.yaml ^
  --universe-name CP_RATE_CORP ^
  --business-date 2026-01-31 ^
  --clean-target ^
  --run-engine


Yes, good catch. Current `run_demo_integrate_with_Mar.py` stages **all asset classes** into raw tables, but `--run-engine` executes only one universe (`--universe-name`).

Best enhancement path:

1. Add `--run-all-compatible-universes`
- Auto-detect compatible universes from `configs/model_catalog.yaml` using `rf_level1` in your staged metadata.
- Run engine once per universe.
- Write one combined run summary.

2. Add `--universe-names` (multi-value)
- Example: `--universe-names CP_RATE_CORP FX_VOL_G10 IR_RATE_USD`
- More control than one `--universe-name`.

3. Keep current behavior as default
- If neither flag is provided, run single universe as today.

Without code change, current workaround:
1. Run integration script with staging only (`--no-run-engine`).
2. Run `run_demo_layer5_runEngine` in a loop for multiple universes.

If you want, I can implement `--run-all-compatible-universes` and `--universe-names` now.



Implemented.

Updated `src/pipeline/run_demo_integrate_with_Mar.py` to support multi-universe engine runs:

- Added `--universe-names` (explicit list)
- Added `--run-all-compatible-universes` (auto-run based on staged `rf_level1` vs config universes)
- Kept backward compatibility with single `--universe-name`
- Added per-universe success/failure tracking in `run_summary.json` (does not stop whole run if one universe fails)

How to use:

1. Run all compatible universes:
```bash
python -m pipeline.run_demo_integrate_with_Mar ^
  --source-path data\incoming\manual_dataset.xlsx ^
  --raw-path data\raw_manual ^
  --processed-path data\processed_manual ^
  --config-path configs\model_catalog.yaml ^
  --business-date 2026-01-31 ^
  --run-engine ^
  --run-all-compatible-universes
```

2. Run specific universe list:
```bash
python -m pipeline.run_demo_integrate_with_Mar ^
  --source-path data\incoming\manual_dataset.xlsx ^
  --raw-path data\raw_manual ^
  --processed-path data\processed_manual ^
  --config-path configs\model_catalog.yaml ^
  --business-date 2026-01-31 ^
  --run-engine ^
  --universe-names CP_RATE_CORP FX_VOL_G10 IR_RATE_USD
```

3. Old single-universe mode still works:
```bash
python -m pipeline.run_demo_integrate_with_Mar ^
  --source-path data\incoming\manual_dataset.xlsx ^
  --run-engine ^
  --universe-name CP_RATE_CORP
```

Validation done:
- `python -m py_compile src/pipeline/run_demo_integrate_with_Mar.py`
- `python -m pipeline.run_demo_integrate_with_Mar --help`





